{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "name": "data-preparation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uuky-Yw8WmXN"
      },
      "source": [
        "<img src=\"https://static.wincacademy.nl/logos/main-logo.png\" height=200px style=\"height: 200px\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5DrbROOWmXX"
      },
      "source": [
        "!pip install matplotlib --user > /dev/null 2>&1\n",
        "!pip install numpy --user > /dev/null 2>&1\n",
        "!pip install pandas --user > /dev/null 2>&1\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZeHltuXWmXb"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "## CSV\n",
        "\n",
        "Let's talk about the messy part of data analytics: preparing data. Before doing the interesting work of data analytics, we need to:\n",
        "\n",
        "1. Gather the data.\n",
        "2. Structure the data in such a way that we can work with it in our programs.\n",
        "3. Clean the data, which may include dealing with missing or unreasonable values.\n",
        "\n",
        "Here we'll assume gathering the data has been done for us. We'll use a dataset provided by the Dutch *Rijksinstituut voor Volksgezondheid en Milieu* (RIVM, translation: National Institute for Health and Environment). It contains COVID-19 numbers per municipality per day. You should place a copy of the data in a file called `covid-data.csv` located in the same folder as this notebook (be it in Google Colab or locally). You can use the URL below to retrieve it.\n",
        "\n",
        "- Source: Rijksinstituut voor Volksgezondheid en Milieu\n",
        "- Data URL: https://data.rivm.nl/covid-19/COVID-19_aantallen_gemeente_per_dag.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9MrlewSWmXg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "fb7dcaa6-1d8a-450f-96a2-78e4931ee91e"
      },
      "source": [
        "data_loc = 'covid-data.csv'\n",
        "covid_data = open(data_loc).read()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-269ffc20083d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'covid-data.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcovid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'covid-data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iy7qgMUWmXi"
      },
      "source": [
        "Let's take a look at what it looks like by printing the first 1000 characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM4f7Gk8WmXj"
      },
      "source": [
        "print(covid_data[:1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODNw0UStWmXn"
      },
      "source": [
        "That looks pretty chaotic. The data is in a format called `csv`, which is a commonly used format to store and share data.\n",
        "\n",
        "1. A `csv` file contains only text.\n",
        "2. The first line a `csv` file lists column names.\n",
        "3. Each line after that is a datapoint with values for those columns in the same order.\n",
        "\n",
        "Let's look at the first 3 lines instead of the first 1000 characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBkGU88rWmXq"
      },
      "source": [
        "for line in covid_data.split('\\n')[:3]:\n",
        "    print(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCECu9tuWmXs"
      },
      "source": [
        "**1. What are the column names for this dataset? List them here.**\n",
        "\n",
        "\n",
        "- Date_of_report\n",
        "- Date_of_publication\n",
        "- Municipality_code\n",
        "- Municipality_name\n",
        "- Province\n",
        "- Security_region_code\n",
        "- Security_region_name\n",
        "- Municipal_health_service\n",
        "- ROAZ_region\n",
        "- Total_reported\n",
        "- Hospital_admission\n",
        "- Deceased\n",
        "\n",
        "**2. Which character separates the datapoints from each other? Put an `x` in the right box.**\n",
        "\n",
        "- [x] A linebreak\n",
        "- [ ] A tab\n",
        "- [ ] A comma\n",
        "\n",
        "**3. Which character separates the columns within a datapoint from each other?**\n",
        "\n",
        ";\n",
        "\n",
        "### Parsing\n",
        "\n",
        "Let's use this information to read the data into our program in a better way. This is known as [*parsing*](https://en.wikipedia.org/wiki/Parsing). Our goal is to structure the data in such a way that we'll be able to write code like this to make it easier to work with the data:\n",
        "\n",
        "```python\n",
        "# For some datapoint, show me the municipality that it concerns.\n",
        "some_datapoint['Municipality_name']\n",
        "```\n",
        "\n",
        "By answering the questions above we have all the information we need to organize the internal *data structure* in this way.\n",
        "\n",
        "- We know what separates datapoints from each other.\n",
        "- We know how columns are separated within datapoints.\n",
        "- We have the column names for each datapoint.\n",
        "\n",
        "We can use this information to instruct Python -- the programming language we're using here -- to create a *data structure* that we can use like in the example above. Once completed, we'll have *parsed* the CSV file.\n",
        "\n",
        "**4. What is parsing in your own words?**\n",
        "\n",
        "Parsing the data means making the data accessible for reading the information and analyzing the data. It makes the data more readible for programming languages and ourselves because we can separate the raw data into colums and rows. \n",
        "\n",
        "**5. Fill in the right column delimiter in the code cell below to complete the code.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6OSqH-8WmXu"
      },
      "source": [
        "# TODO: Change PLACEHOLDER to the actual delimiter.\n",
        "delimiter = ';'\n",
        "# Make sure the delimiter is surrounded by quotes, for example: delimiter = '<' if the delimiter is <\n",
        "\n",
        "with open(data_loc) as f:\n",
        "    csv_reader = csv.DictReader(f, delimiter=delimiter)\n",
        "    print('Municipality name\\tTotal cases reported')\n",
        "    print('{:=>45}'.format(''))\n",
        "    data_dicts = list(csv_reader)\n",
        "\n",
        "for row in data_dicts[:15]:\n",
        "    print('{:<23} {:<5}'.format(row['Municipality_name'], row['Total_reported']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRwDaXDOWmXw"
      },
      "source": [
        "Note: Your delimiter was not filled in (correctly) if you got one of these errors:\n",
        "\n",
        "```python\n",
        "TypeError: \"delimiter\" must be a 1-character string\n",
        "KeyError: 'Municipality_name'\n",
        "```\n",
        "\n",
        "## Metadata\n",
        "\n",
        "Alright, this is much better that looking at raw text, like we did before parsing. We'll get to even better views of the data later. First, let's take a look at some *metadata* -- data about data.\n",
        "- The number of datapoints\n",
        "- The number of columns\n",
        "- The names of the columns (again)\n",
        "- The number of missing or empty values\n",
        "- The number of unique values in each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukHt1gAWWmX6"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "print(f'Number of datapoints: {len(data_dicts)}')\n",
        "print(f'Number of columns: {len(data_dicts[0])}')\n",
        "print('Column names:')\n",
        "for k in data_dicts[0].keys():\n",
        "    print(f'- {k}')\n",
        "    \n",
        "unique_vals = [set() for _ in data_dicts[0].keys()]\n",
        "missing = 0\n",
        "for datapoint in data_dicts:\n",
        "    for i, val in enumerate(datapoint.values()):\n",
        "        unique_vals[i].add(val)\n",
        "        if val is None or val == '':\n",
        "            missing += 1\n",
        "print(f'Missing/empty values: {missing}')\n",
        "\n",
        "print('Number of unique values:')\n",
        "for i, k in enumerate(data_dicts[0].keys()):\n",
        "    print('- {:<25}{:5}'.format(k, len(unique_vals[i])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x41p1OUhWmX7"
      },
      "source": [
        "**6. Note three questions that you have about the data based on this metadata. It might be something like:**\n",
        "\n",
        "> **\"What is the first and last *date of publication* in the dataset?\"**\n",
        "\n",
        "1. Are all dates of publication the same, or, are these datapoints across all municipalities from the same dates? \n",
        "2. What is the correlation between Total_reported and different municipalities? \n",
        "3. How is the number of deceased people spationally spread over the country? \n",
        "\n",
        "**7. Note another metadata property that you would like to know about that's not listed here.**\n",
        "\n",
        "Type data in de dataset per column.\n",
        "\n",
        "## Working with dates\n",
        "\n",
        "Looking at the metadata is a good way to get a feel for what a dataset looks like, and what type of questions you can answer with it. Let's use our example question to proceed with data preparation:\n",
        "\n",
        "> What is the first and last *date of publication* in the dataset?\n",
        "\n",
        "To answer this question, we can't just assume the first date is at the top and the last date is at the bottom, or vice versa. We need some way to do compare the dates and find out which one is the first and which one is the last. Let's first inspect a few entries in the `Date_of_publication` column to see what they look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2FIGHMCWmX8"
      },
      "source": [
        "print('The current datatype for the Date_of_publication column is:', type(data_dicts[0]['Date_of_publication']))\n",
        "for row in data_dicts[::int(len(data_dicts) / 20)]:\n",
        "    print(row['Date_of_publication'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xupdu-0VWmX-"
      },
      "source": [
        "We see that the data type is `str`, which is short for *string*, the programming term for *text*. We can't do any clever comparing with just text. We need to *parse* these dates to be able to make comparisons between them. \n",
        "\n",
        "Fortunately, the dates are then specified in a certain *date format*. For example, in the Netherlands people often write '24/12/1980' for the 24th day of December in the year 1980. We could specify that format as `DD/MM/YYYY`.\n",
        "\n",
        "- `DD` stands for 'Two numbers that represent the day'.\n",
        "- `MM` stands for 'Two numbers that represent the month'.\n",
        "- `YYYY` stands for 'Four numbers that represent the year'.\n",
        "\n",
        "If they wrote `-` instead of `/`, like so: '24-12-1980', the format would be `DD-MM-YYYY`.\n",
        "\n",
        "**8. What is the *date format* in the `Date_of_publication` column in our dataset?**\n",
        "\n",
        "YYYY-MM-DD\n",
        "\n",
        "**9. Fill in this format in the placeholder in the code block below.**\n",
        "\n",
        "- **Use `%Y` for `YYYY`.**\n",
        "- **Use `%m` for `MM`.**\n",
        "- **Use `%d` for `DD`.**\n",
        "\n",
        "**For example, the Dutch date format ('DD/MM/YYYY' would be `'%d/%m/%Y'`)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG-E9x8aWmX-"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# TODO: Fill in date format for PLACEHOLDER in the next line.\n",
        "date_format = '%Y-%m-%d'\n",
        "# Don't modify anything below this line.\n",
        "\n",
        "for row in data_dicts:\n",
        "    formatted_date = datetime.strptime(row['Date_of_publication'], date_format).date()\n",
        "    row['Date_of_publication'] = formatted_date\n",
        "    \n",
        "print('The new datatype for the Date_of_publication column is:', type(data_dicts[0]['Date_of_publication']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PfxACF6WmX_"
      },
      "source": [
        "If you get an error like the following, your `date_format` is not correct yet.\n",
        "\n",
        "```python\n",
        "ValueError: time data '2020-02-27' does not match format 'PLACEHOLDER'\n",
        "```\n",
        "\n",
        "After filling in `date_format` correctly, you should see a line that confirms that the new datatype for this column is `datetime.date`. Great! Now we can compare the dates in the column and answer our original question:\n",
        "\n",
        "> What is the first and last *date of publication* in the dataset?\n",
        "\n",
        "We can now compare the dates with:\n",
        "\n",
        "- `a > b`: this checks if `a` is *later* than `b`.\n",
        "- `a < b`: this checks if `a` is *earlier* than `b`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxjruLE9WmYA"
      },
      "source": [
        "# We make the assumption that the date of publication of the first datapoint is the only date. \n",
        "first_date_of_publication = data_dicts[0]['Date_of_publication']\n",
        "last_date_of_publication = data_dicts[0]['Date_of_publication']\n",
        "# Then we see if we can find any earlier ones, or later ones.\n",
        "for row in data_dicts:\n",
        "    # Check if this date is earlier than the currently known first date of publication\n",
        "    if row['Date_of_publication'] < first_date_of_publication:\n",
        "        # If so, this is now the new earliest date.\n",
        "        first_date_of_publication = row['Date_of_publication']\n",
        "    # Check if this date is later than the currently known last date of publication\n",
        "    elif row['Date_of_publication'] > last_date_of_publication:\n",
        "        # If so, this is now the new latest date.\n",
        "        last_date_of_publication = row['Date_of_publication']\n",
        "\n",
        "print(f'The first date of publication is {first_date_of_publication}')\n",
        "print(f'The last date of publication is {last_date_of_publication}')\n",
        "print(f'The dataset spans {(last_date_of_publication - first_date_of_publication).days} days')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJYRBT1KWmYC"
      },
      "source": [
        "Cool! We now have a better understanding of what the `Date_of_publication` column looks like.\n",
        "\n",
        "**10. Explain, in your own words, what a string is.**\n",
        "\n",
        "A string is a set of text characters that are not recognized as numbers. We cannot calculate anything based on a string because it is recognized by the computer as text. \n",
        "\n",
        "**11. Explain, in your own words, what a date string is.**\n",
        "\n",
        "A date string is a set of characters in a specific date-format. The computer recognizes this string as a date and can perform calculations/functions based on this date-format. \n",
        "\n",
        "**12. Explain, in your own words, why we converted date strings to a `datetime.date` type.**\n",
        "\n",
        "Because a date-formatted string is still a string. By converting these strings into a datetime.date type, we have converted the string to a workable/calculatable format. \n",
        "\n",
        "## Working with numbers\n",
        "\n",
        "We'd like to wrap up this lesson with a nice visualization of how many COVID cases were reported over time in a certain municipality. For that we not only have to work with strings and dates, but also with *numbers*. We can find the right number in the `Total_reported` column, but again, it's not yet in the right format. It's a string, while it needs to be a number.\n",
        "\n",
        "Let's apply the same strategy that we used with dates before. Note that if you run the cell below multiple times, it will no longer show that the column values used to be a strings -- they were converted the first time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib3EXx7zWmYD"
      },
      "source": [
        "print('The current datatype for the Total_reported column is:', type(data_dicts[0]['Total_reported']))\n",
        "for row in data_dicts:\n",
        "    row['Total_reported'] = int(row['Total_reported'])\n",
        "print('The new datatype for the Total_reported column is:', type(data_dicts[0]['Total_reported']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CdDVpxOWmYE"
      },
      "source": [
        "The new datatype for the `Total_reported` column is `int`, which stands for *integer*. This is the programming term for *whole number*. Bonus: the term for a decimal number is *float*.\n",
        "\n",
        "**13. Which variable in the code snippet below is an integer? (write an `x` in the right box)**\n",
        "\n",
        "```python\n",
        "a = 'Hello, world!'\n",
        "b = 42\n",
        "```\n",
        "\n",
        "- [ ] `a`\n",
        "- [x] `b`\n",
        "\n",
        "**14. Which variable in the code snippet below is an integer? (write an `x` in the right box)**\n",
        "\n",
        "```python\n",
        "a = '42'\n",
        "b = 42\n",
        "```\n",
        "\n",
        "- [ ] `a`\n",
        "- [x] `b`\n",
        "\n",
        "Now that the `Total_reported` column has the correct datatype, let's write a script that tells us the reported number per municipality. For convenience, we first print a list of all the municipalities in the dataset.\n",
        "\n",
        "**15. Choose one of the municipalities printed in the code block below. Then fill it in (exactly as it was displayed) in the next cell and run it to find the total number of reported cases in that municipality.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyaB54mLWmYF"
      },
      "source": [
        "for m in sorted(unique_vals[3]):\n",
        "    if m != '':\n",
        "        print('-', m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt1FFmjAWmYG"
      },
      "source": [
        "# TODO: FILL IN THE MUNICIPALITY YOU'RE INTERESTED IN HERE\n",
        "municipality = 'Zaanstad'\n",
        "# DON'T MODIFY ANYTHING BELOW THIS LINE\n",
        "\n",
        "reported = 0\n",
        "for row in data_dicts:\n",
        "    if row['Municipality_name'] == municipality:\n",
        "        reported += row['Total_reported']\n",
        "print(f'The total number of reported cases in {municipality} is {reported}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFRh1CPGWmYJ"
      },
      "source": [
        "Because we have all the data types in order, we can also easily plot the development of new reported cases for that same municipality. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz-pQ-_PWmYM"
      },
      "source": [
        "new_cases_per_day = defaultdict(int)\n",
        "for row in data_dicts:\n",
        "        if row['Municipality_name'] == municipality:\n",
        "            new_cases_per_day[row['Date_of_publication']] += row['Total_reported']\n",
        "new_cases_per_day = sorted(new_cases_per_day.items(), key=lambda x: x[0])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16,9))\n",
        "ax.plot([date for date, _ in new_cases_per_day], [cases for _, cases in new_cases_per_day])\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Number of new cases');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ0uIX_rWmYN"
      },
      "source": [
        "## Missing Data\n",
        "\n",
        "Finally, a visualization! Let's tackle one final problem: missing data. When we were looking at the metadata, we found that we have $22736$ missing or empty values. Let's print a few datapoints that contain missing values to see what we're dealing with exactly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "repFMS6sWmYO"
      },
      "source": [
        "for i, row in enumerate(data_dicts):\n",
        "    missing_keys = []\n",
        "    for key, val in row.items():\n",
        "        if val == '':\n",
        "            missing_keys.append(key)\n",
        "    if missing_keys:\n",
        "        print(f'Row {i} contains empty values for: {missing_keys}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhWYlDLiWmYP"
      },
      "source": [
        "**16. What column(s) is/are missing most often?**\n",
        "\n",
        "Municipality_code and Municipality_name.\n",
        "\n",
        "Missing data may become a problem if we want to draw comparisons between certain parts of the data. Still, there is no universal and definitive *correct approach* to solving the problem of missing data. In fact, in this case there might actually not be a good way to fill in the missing municipalities here.\n",
        "\n",
        "For the sake of exercise, we will create a new dataset for your chosen municipality where the `Total_reported` new cases will be replaced with the impossible number `-1` from a number of the dates.\n",
        "\n",
        "**17. Why is `-1` an impossible number here?**\n",
        "-1 is geen geldige optie omdat de dataset alleen maar gevallen telt die Covid-19 positief getest zijn, geen mensen die bijvoorbeeld negatief getest zijn. Aangezien de dataset alleen maar positieve getallen bevat, wijst -1 erop dat het een 'impossible number' is omdat het niet in de dataset kan voorkomen als echte value. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvFHgHabWmYQ"
      },
      "source": [
        "noisy_new_cases_per_day = [(date, cases) if np.random.rand() < 0.8\n",
        "                           else (date, -1)\n",
        "                           for date, cases in new_cases_per_day]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16,9))\n",
        "ax.plot([date for date, _ in new_cases_per_day],\n",
        "        [cases for _, cases in new_cases_per_day], '.', label='true data')\n",
        "ax.plot([date for date, _ in noisy_new_cases_per_day],\n",
        "        [cases for _, cases in noisy_new_cases_per_day],\n",
        "        label='noisy data')\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Number of new cases')\n",
        "ax.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRyRgtxtWmYR"
      },
      "source": [
        "This plot is a lot more messy than the clean data plot, in addition to also showing the impossible number `-1`.\n",
        "\n",
        "**18. What would be a good way to fill in the missing values? You will not need to implement them, so use your imagination.**\n",
        "\n",
        "We kunnen de missende datum-values schatten door de kijken naar de data-values van de rijen boven en onder de rij met de missende datum-value. Als de lijst namelijk chronologisch is opgesteld kunnen we aannemen dat een lege datum-value ingevuld kan worden door de dichtsbijzinde datum-values te bekijken.\n",
        "\n",
        "Here we'll use the mean of the two surrounding dates' values. For example:\n",
        "\n",
        "1. `2020-02-03` is missing\n",
        "2. We take the values from the day before, `2020-02-02`, and the day after, `2020-02-04`. If the data from the day before or after is not available, we use the nearest available datapoint instead.\n",
        "3. We add them up\n",
        "4. Divide them by $2$\n",
        "5. We insert the result as the value for `2020-02-03`.\n",
        "\n",
        "This is a simple way of doing **interpolation** -- estimating missing values within the range of the data we have. This is the opposite of **extrapolation**, where we have estimate values *outside* of the range of the data we have.\n",
        "\n",
        "Let's see what the implementation and the result look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5Sb-z0nWmYT"
      },
      "source": [
        "interpolated_data = []\n",
        "max_data_index = len(noisy_new_cases_per_day) - 1\n",
        "for i, (date, x) in enumerate(noisy_new_cases_per_day):\n",
        "    # If we have an impossible value\n",
        "    if x == -1:\n",
        "        # Scan the left side for values that are not -1\n",
        "        delta_left = 0\n",
        "        try:\n",
        "            while noisy_new_cases_per_day[i - delta_left][1] == -1:\n",
        "                delta_left += 1\n",
        "                # If we're outside of the data we can't do interpolation. It would be extrapolation.\n",
        "                if i - delta_left < 0:\n",
        "                    raise IndexError\n",
        "        except IndexError:\n",
        "            continue\n",
        "        \n",
        "        # Scan the right side for values that are not -1\n",
        "        delta_right = 0\n",
        "        try:\n",
        "            while noisy_new_cases_per_day[i + delta_right][1] == -1:\n",
        "                delta_right += 1\n",
        "                # If we're outside of the data we can't do interpolation. It would be extrapolation.\n",
        "                if i + delta_right > max_data_index:\n",
        "                    raise IndexError\n",
        "        except IndexError:\n",
        "            continue\n",
        "            \n",
        "        # Finally use the mean of two nearest useful values\n",
        "        interpolated_value = ((noisy_new_cases_per_day[i - delta_left][1]\n",
        "                               + noisy_new_cases_per_day[i + delta_right][1])\n",
        "                              / 2)\n",
        "        interpolated_data.append((date, interpolated_value))\n",
        "    else:\n",
        "        interpolated_data.append((date, x))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16,9))\n",
        "ax.plot([date for date, _ in new_cases_per_day],\n",
        "        [cases for _, cases in new_cases_per_day], '.', label='true data')\n",
        "ax.plot([date for date, _ in interpolated_data],\n",
        "        [cases for _, cases in interpolated_data],\n",
        "        label='interpolated data')\n",
        "ax.plot([date for (date, cases) in noisy_new_cases_per_day if cases == -1],\n",
        "        [cases for _, cases in noisy_new_cases_per_day if cases == -1], '.',\n",
        "        label='previously missing data')\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Number of new cases')\n",
        "ax.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PM4VpvDWmYU"
      },
      "source": [
        "**19. Is this a good way to fill in missing values, in your opinion? Explain.**\n",
        "\n",
        "Dat ligt eraan hoe belangrijk het is of de datums precies kloppen voor hetgeen je wil analyseren. Aangezien de datums missen, kunnen we alleen maar gokken: we zullen het nooit zeker weten of de door ons berekende datum echt precies klopt. Wanneer we heel nauwkeurig in de datum moeten zijn, is het dus een onvoldoende betrouwbare manier. Wanneer de exacte datum niet uitmaakt (als het niet erg is als we er een dag naast zitten), is het een goede manier om de data alsnog te kunnen gebruiken. \n",
        "\n",
        "**20. In which cases will this way of filling in missing values work well, and when will it not work well at all? Give an example for both cases.**\n",
        "\n",
        "Stel dat we berekeningen gaan maken die op de dag nauwkeurig moeten zijn, is het beter om de entries met missing data er uit te laten. Bijvoorbeeld: hoeveel cases waren er per dag in bepaalde gemeenten? Hiervoor hebben we zulke specifieke datum-values nodig dat deze te belangrijk zijn om zelf te berekenen. Voor de betrouwbaarheid van het onderzoek moeten we de daadwerkelijke values hebben en moeten we data met missing values weglaten. \n",
        "\n",
        "Wanneer we over bijvoorbeeld berekeningen maken om hele maanden met elkaar te vergelijken, is het beter mogelijk om op bovenstaande manier datum-values alsnog in te vullen omdat dat daarvoor betrouwbaar genoeg is. Als we het aantal cases over de maanden maart - september over verschillende gemeentes berekenen,  maakt het namelijk niet uit of een case op bijvoorbeeld 12 of 13 maart was. Daarom is bovenstaande methode wel geschikt voor vergelijkingen en berekeningen voor grotere tijdsspannen. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9z_qK-PWmYU"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Data preparation may not be the most glamorous part of data analytics, but it is quite important. If we do not do it well, every analytics step that comes after will suffer. It is as they say: *garbage in, garbage out*.\n",
        "\n",
        "It is also good to know that since most data preparation steps are quite general, there are plenty of tools that make doing it a lot easier and faster. All of the above filtering, selecting and interpolating can be done in a few lines of code! But now *you* know how it works under the hood, and why it's so important!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sv0oOCGWmYV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}